{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/anishmitagar/Documents/repos/summer_2023_projects/end-to-end-diabetes-project/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/anishmitagar/Documents/repos/summer_2023_projects/end-to-end-diabetes-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/anishmitagar/Documents/repos/summer_2023_projects/end-to-end-diabetes-project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from box.config_box import ConfigBox\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    save_path_best_acc: Path\n",
    "    save_path_best_f1: Path\n",
    "    neural_network_params: ConfigBox\n",
    "    random_forest_params: ConfigBox\n",
    "    xg_boost_params: ConfigBox\n",
    "    cat_boost_params: ConfigBox\n",
    "    ada_boost_params: ConfigBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlClassifier.constants import *\n",
    "from mlClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        \n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        create_directories([config.save_path_best_acc])\n",
    "        create_directories([config.save_path_best_f1])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            save_path_best_acc = config.save_path_best_acc,\n",
    "            save_path_best_f1 = config.save_path_best_f1,\n",
    "            neural_network_params = self.params.neural_network_params,\n",
    "            random_forest_params = self.params.random_forest_params,\n",
    "            xg_boost_params = self.params.xg_boost_params,\n",
    "            cat_boost_params = self.params.cat_boost_params,\n",
    "            ada_boost_params = self.params.ada_boost_params\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import copy\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(15, 15)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(15, 15)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(15, 15)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(15, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(device, model, X_train, y_train, X_val, y_val, epochs, lr, batch_size):\n",
    "    model.to(device)\n",
    "    X_val = X_val.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    n_epochs = epochs   # number of epochs to run\n",
    "    batch_size = batch_size  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights_for_acc = None\n",
    "    f1_for_best_acc, precision_for_best_acc, recall_for_best_acc = None, None, None\n",
    "\n",
    "    best_f1 = - np.inf   # init to negative infinity\n",
    "    best_weights_for_f1 = None\n",
    "    acc_for_best_f1, precision_for_best_f1, recall_for_best_f1 = None, None, None\n",
    "\n",
    "    best_precision = - np.inf   # init to negative infinity\n",
    "    best_weights_for_precision = None\n",
    "    acc_for_best_precision, f1_for_best_precision, recall_for_best_precision = None, None, None\n",
    "\n",
    "    best_recall = - np.inf   # init to negative infinity\n",
    "    best_weights_for_recall = None\n",
    "    acc_for_best_recall, f1_for_best_recall, precision_for_best_recall = None, None, None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                y_batch = y_batch.to(device)\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        y_real = y_val.cpu().numpy()\n",
    "        y_try = y_pred.round().detach().cpu().numpy()\n",
    "        # print(metrics.accuracy_score(y_real, y_try), metrics.f1_score(y_real, y_try), metrics.precision_score(y_real, y_try), metrics.recall_score(y_real, y_try))\n",
    "        # acc = (y_pred.round() == y_val).float().mean()\n",
    "        # acc = float(acc)\n",
    "        acc = metrics.accuracy_score(y_real, y_try)\n",
    "        f1 = metrics.f1_score(y_real, y_try)\n",
    "        precision = metrics.precision_score(y_real, y_try)\n",
    "        recall = metrics.recall_score(y_real, y_try)\n",
    "        \n",
    "        #print(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            f1_for_best_acc, precision_for_best_acc, recall_for_best_acc = f1, precision, recall\n",
    "            best_weights_for_acc = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            acc_for_best_f1, precision_for_best_f1, recall_for_best_f1 = acc, precision, recall\n",
    "            best_weights_for_f1 = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            acc_for_best_precision, f1_for_best_precision, recall_for_best_precision = acc, f1, recall\n",
    "            best_weights_for_precision = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            acc_for_best_recall, f1_for_best_recall, precision_for_best_recall = acc, f1, precision\n",
    "            best_weights_for_recall = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    # model.load_state_dict(best_weights)\n",
    "    return [[best_acc, f1_for_best_acc, precision_for_best_acc, recall_for_best_acc], \n",
    "            [best_f1, acc_for_best_f1, precision_for_best_f1, recall_for_best_f1],\n",
    "            [best_precision, acc_for_best_precision, f1_for_best_precision, recall_for_best_precision],\n",
    "            [best_recall, acc_for_best_recall, f1_for_best_recall, precision_for_best_recall]], best_weights_for_acc, best_weights_for_f1, best_weights_for_precision, best_weights_for_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (AdaBoostClassifier, RandomForestClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Grid_CV_RandomForestClassifier(params, X, y):\n",
    "    best_acc, best_f1, best_precision, best_recall = -np.inf, -np.inf, -np.inf, -np.inf\n",
    "    best_model_for_acc, best_model_for_f1, best_model_for_precision, best_model_for_recall = None, None, None, None\n",
    "    for n_estimators in params.n_estimators:\n",
    "        for criterion in params.criterion:\n",
    "            for max_depth in params.max_depth:\n",
    "                clf = RandomForestClassifier(n_estimators = n_estimators, criterion=criterion, max_depth=max_depth)  \n",
    "                np.random.seed(0)\n",
    "                cv = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "                acc, f1, precision, recall = 0, 0, 0, 0\n",
    "                for (train, test), i in zip(cv.split(X, y), range(10)):\n",
    "                    clf.fit(X.iloc[train], y.iloc[train])\n",
    "                    y_pred = clf.predict(X.iloc[test])\n",
    "                    y_test = y.iloc[test]\n",
    "                    acc, f1, precision, recall = metrics.accuracy_score(y_test, y_pred) + acc, metrics.f1_score(y_test, y_pred) + f1, metrics.precision_score(y_test, y_pred) + precision, metrics.recall_score(y_test, y_pred) + recall\n",
    "                acc, f1, precision, recall = acc/10, f1/10, precision/10, recall/10\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_model_for_acc = clf\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_model_for_f1 = clf\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_model_for_precision = clf\n",
    "                if recall > best_recall:\n",
    "                    best_recall = recall\n",
    "                    best_model_for_recall = clf\n",
    "                print(f\"Completed for {n_estimators, criterion, max_depth}\")\n",
    "    return {\"best_acc\": (best_acc, best_model_for_acc),\n",
    "            \"best_f1\": (best_f1, best_model_for_f1),\n",
    "            \"best_precision\": (best_recall, best_model_for_precision),\n",
    "            \"best_recall\": (best_precision, best_model_for_recall)}\n",
    "\n",
    "def train_Grid_CV_XGBClassifier(params, X, y):\n",
    "    best_acc, best_f1, best_precision, best_recall = -np.inf, -np.inf, -np.inf, -np.inf\n",
    "    best_model_for_acc, best_model_for_f1, best_model_for_precision, best_model_for_recall = None, None, None, None\n",
    "    for n_estimators in params.n_estimators:\n",
    "        for learning_rate in params.learning_rate:\n",
    "            for max_depth in params.max_depth:\n",
    "                clf = XGBClassifier(n_estimators = n_estimators, learning_rate=learning_rate, max_depth=max_depth)  \n",
    "                np.random.seed(0)\n",
    "                cv = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "                acc, f1, precision, recall = 0, 0, 0, 0\n",
    "                for (train, test), i in zip(cv.split(X, y), range(10)):\n",
    "                    clf.fit(X.iloc[train], y.iloc[train])\n",
    "                    y_pred = clf.predict(X.iloc[test])\n",
    "                    y_test = y.iloc[test]\n",
    "                    acc, f1, precision, recall = metrics.accuracy_score(y_test, y_pred) + acc, metrics.f1_score(y_test, y_pred) + f1, metrics.precision_score(y_test, y_pred) + precision, metrics.recall_score(y_test, y_pred) + recall\n",
    "                acc, f1, precision, recall = acc/10, f1/10, precision/10, recall/10\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_model_for_acc = clf\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_model_for_f1 = clf\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_model_for_precision = clf\n",
    "                if recall > best_recall:\n",
    "                    best_recall = recall\n",
    "                    best_model_for_recall = clf\n",
    "                print(f\"Completed for {n_estimators, learning_rate, max_depth}\")\n",
    "    return {\"best_acc\": (best_acc, best_model_for_acc),\n",
    "            \"best_f1\": (best_f1, best_model_for_f1),\n",
    "            \"best_precision\": (best_recall, best_model_for_precision),\n",
    "            \"best_recall\": (best_precision, best_model_for_recall)}\n",
    "\n",
    "def train_Grid_CV_CatBoostClassifier(params, X, y):\n",
    "    best_acc, best_f1, best_precision, best_recall = -np.inf, -np.inf, -np.inf, -np.inf\n",
    "    best_model_for_acc, best_model_for_f1, best_model_for_precision, best_model_for_recall = None, None, None, None\n",
    "    for iterations in params.iterations:\n",
    "        for learning_rate in params.learning_rate:\n",
    "            for depth in params.depth:\n",
    "                clf = CatBoostClassifier(iterations = iterations, learning_rate=learning_rate, depth=depth, verbose=False)  \n",
    "                np.random.seed(0)\n",
    "                cv = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "                acc, f1, precision, recall = 0, 0, 0, 0\n",
    "                for (train, test), i in zip(cv.split(X, y), range(10)):\n",
    "                    clf.fit(X.iloc[train], y.iloc[train])\n",
    "                    y_pred = clf.predict(X.iloc[test])\n",
    "                    y_test = y.iloc[test]\n",
    "                    acc, f1, precision, recall = metrics.accuracy_score(y_test, y_pred) + acc, metrics.f1_score(y_test, y_pred) + f1, metrics.precision_score(y_test, y_pred) + precision, metrics.recall_score(y_test, y_pred) + recall\n",
    "                acc, f1, precision, recall = acc/10, f1/10, precision/10, recall/10\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_model_for_acc = clf\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_model_for_f1 = clf\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_model_for_precision = clf\n",
    "                if recall > best_recall:\n",
    "                    best_recall = recall\n",
    "                    best_model_for_recall = clf\n",
    "                print(f\"Completed for {iterations, learning_rate, depth}\")\n",
    "    return {\"best_acc\": (best_acc, best_model_for_acc),\n",
    "            \"best_f1\": (best_f1, best_model_for_f1),\n",
    "            \"best_precision\": (best_recall, best_model_for_precision),\n",
    "            \"best_recall\": (best_precision, best_model_for_recall)}\n",
    "\n",
    "def train_Grid_CV_AdaBoostClassifier(params, X, y):\n",
    "    best_acc, best_f1, best_precision, best_recall = -np.inf, -np.inf, -np.inf, -np.inf\n",
    "    best_model_for_acc, best_model_for_f1, best_model_for_precision, best_model_for_recall = None, None, None, None\n",
    "    for n_estimators in params.n_estimators:\n",
    "        for learning_rate in params.learning_rate:\n",
    "            clf = AdaBoostClassifier(n_estimators = n_estimators, learning_rate=learning_rate)  \n",
    "            np.random.seed(0)\n",
    "            cv = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "            acc, f1, precision, recall = 0, 0, 0, 0\n",
    "            for (train, test), i in zip(cv.split(X, y), range(10)):\n",
    "                clf.fit(X.iloc[train], y.iloc[train])\n",
    "                y_pred = clf.predict(X.iloc[test])\n",
    "                y_test = y.iloc[test]\n",
    "                acc, f1, precision, recall = metrics.accuracy_score(y_test, y_pred) + acc, metrics.f1_score(y_test, y_pred) + f1, metrics.precision_score(y_test, y_pred) + precision, metrics.recall_score(y_test, y_pred) + recall\n",
    "            acc, f1, precision, recall = acc/10, f1/10, precision/10, recall/10\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model_for_acc = clf\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model_for_f1 = clf\n",
    "            if precision > best_precision:\n",
    "                best_precision = precision\n",
    "                best_model_for_precision = clf\n",
    "            if recall > best_recall:\n",
    "                best_recall = recall\n",
    "                best_model_for_recall = clf\n",
    "            print(f\"Completed for {n_estimators, learning_rate}\")\n",
    "    return {\"best_acc\": (best_acc, best_model_for_acc),\n",
    "            \"best_f1\": (best_f1, best_model_for_f1),\n",
    "            \"best_precision\": (best_recall, best_model_for_precision),\n",
    "            \"best_recall\": (best_precision, best_model_for_recall)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import dill\n",
    "import pickle\n",
    "\n",
    "def save_object(file_path, obj):\n",
    "\n",
    "    dir_path = os.path.dirname(file_path)\n",
    "\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    with open(file_path, \"wb\") as file_obj:\n",
    "        dill.dump(obj, file_obj)\n",
    "    \n",
    "\n",
    "    \n",
    "def load_object(file_path):\n",
    "\n",
    "    with open(file_path, \"rb\") as file_obj:\n",
    "        return pickle.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        df = pd.read_csv(self.config.data_path)\n",
    "\n",
    "        X, y = df.drop(columns=['diabetes'],axis=1), df['diabetes']\n",
    "\n",
    "        X_tensor = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y.to_numpy(), dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "        best_acc = -np.inf\n",
    "        best_acc_model = None\n",
    "        best_f1 = -np.inf\n",
    "        best_f1_model = None\n",
    "       \n",
    "        print(\"Training Neural Network\")\n",
    "        nn_results = self._train_nn(self.config.neural_network_params, X_tensor, y_tensor)\n",
    "        if nn_results[\"best_acc\"][0] > best_acc:\n",
    "            best_acc, best_acc_model = nn_results[\"best_acc\"][0], nn_results[\"best_acc\"][1]\n",
    "        if nn_results[\"best_f1\"][0] > best_f1:\n",
    "            best_f1, best_f1_model = nn_results[\"best_f1\"][0], nn_results[\"best_f1\"][1]  \n",
    "        print(\"Finshed Training Neural Network\")\n",
    "\n",
    "        print(\"Training Random Forest\")\n",
    "        random_forest_results = train_Grid_CV_RandomForestClassifier(self.config.random_forest_params, X, y)\n",
    "        if random_forest_results[\"best_acc\"][0] > best_acc:\n",
    "            best_acc, best_acc_model = random_forest_results[\"best_acc\"][0], random_forest_results[\"best_acc\"][1] \n",
    "        if random_forest_results[\"best_f1\"][0] > best_f1:\n",
    "            best_f1, best_f1_model = random_forest_results[\"best_f1\"][0], random_forest_results[\"best_f1\"][1]  \n",
    "        print(\"Finished training Random Forest\")\n",
    "\n",
    "        print(\"Training XGBClassifier\")\n",
    "        xgb_results = train_Grid_CV_XGBClassifier(self.config.xg_boost_params, X, y)\n",
    "        if xgb_results[\"best_acc\"][0] > best_acc:\n",
    "            best_acc, best_acc_model = xgb_results[\"best_acc\"][0], xgb_results[\"best_acc\"][1]  \n",
    "        if xgb_results[\"best_f1\"][0] > best_f1: \n",
    "            best_f1, best_f1_model = xgb_results[\"best_f1\"][0], xgb_results[\"best_f1\"][1]\n",
    "        print(\"Finished training XGBClassifier\")\n",
    "\n",
    "        print(\"Training CatBoostClassifier\")\n",
    "        cat_boost_results = train_Grid_CV_CatBoostClassifier(self.config.cat_boost_params, X, y)\n",
    "        if cat_boost_results[\"best_acc\"][0] > best_acc:\n",
    "            best_acc, best_acc_model = cat_boost_results[\"best_acc\"][0], cat_boost_results[\"best_acc\"][1]  \n",
    "        if cat_boost_results[\"best_f1\"][0] > best_f1:\n",
    "            best_f1, best_f1_model = cat_boost_results[\"best_f1\"][0], cat_boost_results[\"best_f1\"][1]  \n",
    "        print(\"Finished training CatBoostClassifier\")\n",
    "\n",
    "        print(\"Training AdaBoostClassifier\")\n",
    "        ada_boost_results = train_Grid_CV_AdaBoostClassifier(self.config.ada_boost_params, X, y)\n",
    "        if ada_boost_results[\"best_acc\"][0] > best_acc: \n",
    "            best_acc, best_acc_model = ada_boost_results[\"best_acc\"][0], ada_boost_results[\"best_acc\"][1]  \n",
    "        if ada_boost_results[\"best_f1\"][0] > best_f1:\n",
    "            best_f1, best_f1_model = ada_boost_results[\"best_f1\"][0], ada_boost_results[\"best_f1\"][1]  \n",
    "        print(\"Finished training AdaBoostClassifier\")\n",
    "\n",
    "        if type(best_acc_model) is collections.OrderedDict:\n",
    "            torch.save(best_acc_model, \"artifacts/model_trainer/best_acc_model/model.pth\")\n",
    "        else:\n",
    "            save_object(file_path=\"artifacts/model_trainer/best_acc_model/model.pkl\", obj = best_acc_model)\n",
    "\n",
    "        if type(best_f1_model) is collections.OrderedDict:\n",
    "            torch.save(best_f1_model, \"artifacts/model_trainer/best_f1_model/model.pth\")\n",
    "        else:\n",
    "            save_object(file_path=\"artifacts/model_trainer/best_f1_model/model.pkl\", obj = best_acc_model)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _train_nn(params, X_tensor, y_tensor):\n",
    "        best_weights_for_acc, best_weights_for_f1, best_weights_for_precision, best_weights_for_recall = None, None, None, None\n",
    "        best_avg_acc, best_avg_f1, best_avg_precision, best_avg_recall = - np.inf, - np.inf, - np.inf, - np.inf\n",
    "        device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "        for epochs in params.epochs:\n",
    "            for lr in params.lrs:\n",
    "                for batch_size in params.batch_sizes:\n",
    "                    print(epochs, lr, batch_size)\n",
    "                    warnings.filterwarnings('ignore')\n",
    "                    # define 5-fold cross validation test harness\n",
    "                    np.random.seed(0)\n",
    "                    kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "                    #cv_scores = []\n",
    "                    sum_results = np.zeros((4, 4))\n",
    "                    for train, test in kfold.split(X_tensor, y_tensor):\n",
    "                        torch.manual_seed(0)\n",
    "                        model = Deep().apply(weights_init)\n",
    "                        results, weights_for_acc, weights_for_f1, weights_for_precision, weights_for_recall = model_train(device, model, X_tensor[train], y_tensor[train], X_tensor[test], y_tensor[test], epochs, lr, batch_size)\n",
    "                        sum_results = np.add(sum_results, np.array(results))\n",
    "                    sum_results = sum_results/10\n",
    "                    if sum_results[0][0] > best_avg_acc:\n",
    "                        best_avg_acc = sum_results[0][0]\n",
    "                        best_weights_for_acc = weights_for_acc\n",
    "                    if sum_results[1][0] > best_avg_f1:\n",
    "                        best_avg_f1 = sum_results[1][0]\n",
    "                        best_weights_for_f1 = weights_for_f1\n",
    "                    if sum_results[2][0] > best_avg_precision:\n",
    "                        best_avg_precision = sum_results[2][0]\n",
    "                        best_weights_for_precision = weights_for_precision\n",
    "                    if sum_results[3][0] > best_avg_recall:\n",
    "                        best_avg_recall = sum_results[3][0]\n",
    "                        best_weights_for_recall = weights_for_recall\n",
    "        return {\"best_acc\": (best_avg_acc, best_weights_for_acc),\n",
    "                \"best_f1\": (best_avg_f1, best_weights_for_f1),\n",
    "                \"best_precision\": (best_avg_recall, best_weights_for_precision),\n",
    "                \"best_recall\": (best_avg_precision, best_weights_for_recall)}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-22 10:34:32,870: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2023-07-22 10:34:32,872: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-07-22 10:34:32,873: INFO: common: created directory at: artifacts]\n",
      "[2023-07-22 10:34:32,873: INFO: common: created directory at: artifacts/model_trainer]\n",
      "[2023-07-22 10:34:32,874: INFO: common: created directory at: artifacts/model_trainer/best_acc_model]\n",
      "[2023-07-22 10:34:32,874: INFO: common: created directory at: artifacts/model_trainer/best_f1_model]\n",
      "Training Neural Network\n",
      "50 1e-05 2500\n",
      "Finshed Training Neural Network\n",
      "Training Random Forest\n",
      "Completed for (50, 'gini', 10)\n",
      "Finished training Random Forest\n",
      "Training XGBClassifier\n",
      "Completed for (8, 0.1, 3)\n",
      "Finished training XGBClassifier\n",
      "Training CatBoostClassifier\n",
      "Completed for (30, 0.01, 6)\n",
      "Finished training CatBoostClassifier\n",
      "Training AdaBoostClassifier\n",
      "Completed for (8, 0.1)\n",
      "Finished training AdaBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(model_trainer_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
